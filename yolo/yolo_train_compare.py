import argparse
import glob
import logging
import os
from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any

import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import pandas as pd
import torch
from ultralytics import YOLO
from ultralytics.engine.results import Results


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ModelConfig:
    model_path: str
    data_path: str
    model_name: str
    save_dir: str
    epochs: int = 78
    imgsz: int = 640
    batch: int = 8
    device: str = "cuda"
    workers: int = 0

    
class ModelTrainer:
    def __init__(self, config: ModelConfig):
        self.config = config

    def train(self) -> str:
        logger.info(f"--- –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {self.config.model_name} ---")
        try:
            model = YOLO(self.config.model_path)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            results = model.train(
                data=self.config.data_path,
                epochs=self.config.epochs,
                imgsz=self.config.imgsz,
                batch=self.config.batch,
                device=self.config.device,
                workers=self.config.workers,
                name=f"train_{self.config.model_name}",
                project=self.config.save_dir,
                verbose=True
            )

            weights_dir = self._get_weights_dir(results, model)
            best_weights = os.path.join(weights_dir, "weights", "best.pt")
            logger.info(f"Best weights saved at: {best_weights}")
            return best_weights

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}", exc_info=True)
            raise

    def _get_weights_dir(self, results, model) -> str:
        if hasattr(results, "save_dir"):
            return results.save_dir
        elif hasattr(model, "trainer") and hasattr(model.trainer, "save_dir"):
            return model.trainer.save_dir
        return os.path.join(self.config.save_dir, f"train_{self.config.model_name}")


class ModelEvaluator:
    def __init__(self, model_path: str):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞
        self.model = YOLO(model_path).to('cpu')

    def evaluate(self, test_image_path: str, save_vis_dir: Optional[str] = None, prefix: str = "", device: str = "cpu") -> Dict[str, Any]:
        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ device –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –º–µ—Ç–æ–¥ model()
        try:
            # –£—Å—Ç—Ä–∞–Ω–µ–Ω–∞ –¥—É–±–ª–∏—Ä—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ results = self.model(test_image_path)
            results = self.model(test_image_path, device=device) 
            metrics = {}
            no_tumor_data = None

            for idx, result in enumerate(results):
                if hasattr(result, 'boxes') and len(result.boxes) > 0:
                    best_box, class_name = self._process_detection(result)

                    if class_name in ['Glioma', 'Meningioma', 'Pituitary']:
                        logger.info(f"üü¢ –í—ã–±—Ä–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {class_name}")
                        self._save_prediction(best_box, result, test_image_path, save_vis_dir, prefix, idx)
                    else:
                        no_tumor_data = (best_box, result, idx, class_name)

                    metrics.update(self._calculate_metrics(best_box))
                else:
                    logger.warning("–ù–µ—Ç –±–æ–∫—Å–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")
                    metrics.update({'avg_confidence': 'N/A', 'max_confidence': 'N/A'})

            if no_tumor_data:
                logger.info(f"üî¥ –°–æ—Ö—Ä–∞–Ω—è–µ–º No tumor –≤ –∫–æ–Ω—Ü–µ: {no_tumor_data[3]}")
                self._save_prediction(
                    best_box=no_tumor_data[0],
                    result=no_tumor_data[1],
                    test_image_path=test_image_path,
                    save_vis_dir=save_vis_dir,
                    prefix=prefix,
                    idx=no_tumor_data[2])

            return metrics

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –º–æ–¥–µ–ª–∏: {str(e)}", exc_info=True)
            raise

    def _process_detection(self, result) -> Tuple[Any, str]:
        confs = result.boxes.conf.cpu().numpy()
        max_idx = confs.argmax()
        best_box = result.boxes[max_idx:max_idx+1]
        class_id = int(best_box.cls.cpu().numpy()[0])
        return best_box, result.names[class_id]

    def _calculate_metrics(self, best_box) -> Dict[str, float]:
        conf = best_box.conf.cpu().numpy()[0]
        return {'avg_confidence': conf, 'max_confidence': conf}

    def _save_prediction(self, best_box: Any, result: Results, test_image_path: str, 
                         save_vis_dir: Optional[str], prefix: str, idx: int) -> None:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ñ–∏–≥—É—Ä—É –∏ –æ—Å–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –†–∞–∑–º–µ—Ä figsize –∏ dpi –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
        fig, ax = plt.subplots(figsize=(result.orig_img.shape[1] / 100, result.orig_img.shape[0] / 100), dpi=100)
        
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç Results —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –±–æ–∫—Å–æ–º –¥–ª—è plot
            best_result = Results(
                orig_img=result.orig_img,
                path=result.path,
                names=result.names
            )
            best_result.boxes = best_box
            best_result.masks = None # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–∞—Å–∫–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω—ã
            best_result.probs = None # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ probs –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω—ã

            # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–¥—Ä (numpy array)
            annotated_frame = best_result.plot()
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –µ–≥–æ –Ω–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –æ—Å—è—Ö
            ax.imshow(annotated_frame)
            ax.axis('off') # –£–±–∏—Ä–∞–µ–º –æ—Å–∏

            if save_vis_dir:
                os.makedirs(save_vis_dir, exist_ok=True)
                class_id = int(best_box.cls.cpu().numpy()[0])
                class_name = result.names[class_id]
                file_basename = os.path.basename(test_image_path).replace('.', f'_pred_{idx+1}.')
                outname = f"{class_name}_{file_basename}"
                save_path = os.path.join(save_vis_dir, outname)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∏–≥—É—Ä—É (fig)
                fig.savefig(save_path, bbox_inches='tight', pad_inches=0)
                logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}", exc_info=True)
            raise
        finally:
            # –û–ß–ï–ù–¨ –í–ê–ñ–ù–û: –ó–∞–∫—Ä—ã—Ç—å —Ñ–∏–≥—É—Ä—É, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã Matplotlib –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            plt.close(fig) 


class ModelComparator:
    @staticmethod
    def compare(model1_path: str, model2_path: str, model1_name: str, model2_name: str, 
                test_image_path: str, save_vis_dir: Optional[str] = None) -> Optional[str]:
        try:
            logger.info("\n--- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ---")
            evaluator1 = ModelEvaluator(model1_path)
            evaluator2 = ModelEvaluator(model2_path)

            metrics1 = evaluator1.evaluate(test_image_path, save_vis_dir, prefix=model1_name + "_")
            metrics2 = evaluator2.evaluate(test_image_path, save_vis_dir, prefix=model2_name + "_")

            comparison_df = pd.DataFrame({
                'Metric': ['Average Confidence', 'Max Confidence'],
                model1_name: [metrics1.get('avg_confidence', 'N/A'), metrics1.get('max_confidence', 'N/A')],
                model2_name: [metrics2.get('avg_confidence', 'N/A'), metrics2.get('max_confidence', 'N/A')]
            })

            logger.info("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫:")
            logger.info(comparison_df)

            if 'avg_confidence' in metrics1 and 'avg_confidence' in metrics2:
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ 'N/A'
                conf1 = metrics1['avg_confidence'] if isinstance(metrics1['avg_confidence'], (int, float)) else -1
                conf2 = metrics2['avg_confidence'] if isinstance(metrics2['avg_confidence'], (int, float)) else -1

                if conf1 > conf2:
                    logger.info(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {model1_name} (—Å—Ä–µ–¥–Ω–∏–π confidence: {metrics1['avg_confidence']:.2f})")
                    return model1_path
                else:
                    logger.info(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {model2_name} (—Å—Ä–µ–¥–Ω–∏–π confidence: {metrics2['avg_confidence']:.2f})")
                    return model2_path
            else:
                logger.warning("\n–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ä–∞–≤–Ω–∏—Ç—å –º–æ–¥–µ–ª–∏ –ø–æ confidence. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–π.")
                return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π: {str(e)}", exc_info=True)
            raise


class InferencePipeline:
    @staticmethod
    def run_inference(best_model: str, media_root: str, single_folder_id: Optional[str] = None, device: str = "cpu") -> None:
        try:
            logger.info(f"\n=== –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {best_model} ===")
            evaluator = ModelEvaluator(best_model)
            # –í–ê–ñ–ù–û: –£–î–ê–õ–ï–ù–ê —Å—Ç—Ä–æ–∫–∞ evaluator.model = YOLO(best_model), 
            # —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ ModelEvaluator.__init__

            if single_folder_id:
                target_dir = os.path.join(media_root, single_folder_id, "raw")
                if not os.path.exists(target_dir):
                    logger.error(f"–ü–∞–ø–∫–∞ {target_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                    raise FileNotFoundError(f"Folder not found: {target_dir}")
                all_raw_images = glob.glob(os.path.join(target_dir, "*.png"))
                logger.info(f"–ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–∞–ø–∫–∏: {single_folder_id}/raw")
            else:
                all_raw_images = glob.glob(os.path.join(media_root, "*", "raw", "*.png"))
                logger.info(f"–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫ –≤: {media_root}")

            if not all_raw_images:
                logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞!")
                raise FileNotFoundError("No images found for inference")

            for img_path in all_raw_images:
                base_dir = os.path.dirname(os.path.dirname(img_path))
                predict_dir = os.path.join(base_dir, "predict")
                os.makedirs(predict_dir, exist_ok=True)
                logger.info(f"\n--- –ü—Ä–µ–¥–∏–∫—Ç –¥–ª—è {img_path} ---")
                evaluator.evaluate(
                    test_image_path=img_path,
                    save_vis_dir=predict_dir,
                    prefix="",
                    device=device) # –ü–µ—Ä–µ–¥–∞–µ–º device

            logger.info("\n–í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {str(e)}", exc_info=True)
            raise


def main():
    try:
        parser = argparse.ArgumentParser()
        parser.add_argument("--predict_only", action="store_true", help="–¢–æ–ª—å–∫–æ –ø—Ä–µ–¥–∏–∫—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω)")
        parser.add_argument("--data_path", type=str, help="–ü—É—Ç—å –∫ data.yaml")
        parser.add_argument("--model1_name", type=str, default="yolo11n")
        parser.add_argument("--model1_weights", type=str, help="–í–µ—Å–∞ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏")
        parser.add_argument("--model2_name", type=str, default="yolov8n")
        parser.add_argument("--model2_weights", type=str, help="–í–µ—Å–∞ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏")
        parser.add_argument("--epochs", type=int, default=30)
        parser.add_argument("--imgsz", type=int, default=640)
        parser.add_argument("--batch", type=int, default=8)
        parser.add_argument("--media_root", type=str, default="media/png", help="–ö–æ—Ä–µ–Ω—å —Å media/png/001, 002, ...")
        parser.add_argument("--yolo_dir", type=str, default="media/yolo/yoloruns", help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤–µ—Å–∞ –∏ runs YOLO")
        parser.add_argument("--single_folder_id", type=str, help="ID –ø–∞–ø–∫–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 007)")
        args = parser.parse_args()

        save_root = args.yolo_dir
        os.makedirs(save_root, exist_ok=True)

        best_model_file = os.path.join(save_root, "best_model.txt")

        if not os.path.isfile(best_model_file):
            logger.info("\n=== –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç best_model.txt ===")

            trainer1 = ModelTrainer(ModelConfig(
                model_path=args.model1_weights,
                data_path=args.data_path,
                model_name=args.model1_name,
                save_dir=save_root,
                epochs=args.epochs,
                imgsz=args.imgsz,
                batch=args.batch
            ))
            model1_weights = trainer1.train()

            trainer2 = ModelTrainer(ModelConfig(
                model_path=args.model2_weights,
                data_path=args.data_path,
                model_name=args.model2_name,
                save_dir=save_root,
                epochs=args.epochs,
                imgsz=args.imgsz,
                batch=args.batch
            ))
            model2_weights = trainer2.train()

            test_images = glob.glob("media/png/testimage/*.png")
            if not test_images:
                logger.error("–ù–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ media/png/testimage!")
                raise FileNotFoundError("No test images found")

            best_model = ModelComparator.compare(
                model1_path=model1_weights,
                model2_path=model2_weights,
                model1_name=args.model1_name,
                model2_name=args.model2_name,
                test_image_path=test_images[0],
                save_vis_dir=None
            )

            with open(best_model_file, "w") as f:
                f.write(best_model if best_model else "")
        else:
            with open(best_model_file, "r") as f:
                best_model = f.read().strip()

        if best_model:
            InferencePipeline.run_inference(
                best_model=best_model,
                media_root=args.media_root,
                single_folder_id=args.single_folder_id
            )

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ main: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    main()